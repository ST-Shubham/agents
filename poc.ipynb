{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Enum for LLMProvider Options\n",
    "from enum import Enum\n",
    "class LLMProvider(Enum):\n",
    "    OPENAI = \"openai\"\n",
    "    GEMINI = \"gemini\"\n",
    "    ANTHROPIC = \"anthropic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9097dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Base Config which will be implemented by model specific configs\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from typing import Optional\n",
    "\n",
    "class BaseAgentConfig(BaseModel):\n",
    "    model_config = ConfigDict(extra=\"forbid\")\n",
    "    model: str\n",
    "    temperature: Optional[float] = None\n",
    "    max_tokens: Optional[int] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd8043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provider Specific Config Extensions\n",
    "from typing import Dict, Any\n",
    "\n",
    "class OpenAIConfig(BaseAgentConfig):\n",
    "    top_p: Optional[float] = None\n",
    "    presence_penalty: Optional[float] = None\n",
    "    frequency_penalty: Optional[float] = None\n",
    "\n",
    "\n",
    "class GeminiConfig(BaseAgentConfig):\n",
    "    safety_settings: Optional[Dict[str, Any]] = None\n",
    "    top_k: Optional[int] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada09702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for messages\n",
    "from typing import List, Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Message(BaseModel):\n",
    "    role: Literal[\"system\", \"user\", \"assistant\", \"tool\"]\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de958b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Provider class (llm-provider)\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Generator, Dict, Any, List, Type\n",
    "\n",
    "class LLMProvider(ABC):\n",
    "    config_schema: Type[BaseAgentConfig]\n",
    "\n",
    "    def __init__(self, config: BaseAgentConfig, system_message: str):\n",
    "        self.config = config\n",
    "        self.system_message = system_message\n",
    "        \n",
    "        self.history: List[Message] = [\n",
    "            Message(role=\"system\", content=system_message)\n",
    "        ]\n",
    "\n",
    "    # -------------------------\n",
    "    # History Management\n",
    "    # -------------------------\n",
    "    def add_user_message(self, content: str):\n",
    "        self.history.append(Message(role=\"user\", content=content))\n",
    "\n",
    "    def add_assistant_message(self, content: str):\n",
    "        self.history.append(Message(role=\"assistant\", content=content))\n",
    "\n",
    "    def rollback(self, steps: int = 1):\n",
    "        \"\"\"Go back N messages (excluding system).\"\"\"\n",
    "        if steps > 0:\n",
    "            self.history = self.history[:-steps]\n",
    "\n",
    "    def save_history(self) -> List[Message]:\n",
    "        return self.history.copy()\n",
    "\n",
    "    def compress_history(self, summarizer: \"LLMProvider\"):\n",
    "        \"\"\"Replace history with a summary.\"\"\"\n",
    "        summary = summarizer.generate(\n",
    "            \"Summarize the following conversation:\\n\"\n",
    "            + \"\\n\".join(m.content for m in self.history)\n",
    "        )\n",
    "        self.history = [\n",
    "            Message(role=\"system\", content=self.system_message),\n",
    "            Message(role=\"assistant\", content=summary)\n",
    "        ]\n",
    "\n",
    "    # -------------------------\n",
    "    # Generation APIs\n",
    "    # -------------------------\n",
    "    @abstractmethod\n",
    "    def generate(self, prompt: str, **kwargs) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_stream(self, prompt: str, **kwargs) -> Generator[str, None, None]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_structured(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        response_schema: Dict[str, Any],\n",
    "        **kwargs\n",
    "    ) -> Dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_tool_calls(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        tools: List[BaseModel],\n",
    "        stream: bool = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    # -------------------------\n",
    "    # Introspection\n",
    "    # -------------------------\n",
    "    @classmethod\n",
    "    def supported_config(cls) -> Dict[str, Any]:\n",
    "        \"\"\"Expose valid config fields to user/dev.\"\"\"\n",
    "        return cls.config_schema.model_json_schema()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
